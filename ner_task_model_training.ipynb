{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "!pip install datasets \n",
    "!pip install ipymarkup\n",
    "!pip install scikit-learn \n",
    "!pip install seqeval\n",
    "!pip install evaluate\n",
    "%pip install git+https://github.com/huggingface/transformers"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "import random\n",
    "from sklearn metrics import classification_report, confusion_matrix \n",
    "from sklearn preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import logging \n",
    "import os\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Optional\n",
    "\n",
    "import datasates\n",
    "import evaluate\n",
    "import tensorflow as tf\n",
    "import transformers\n",
    "from transformers import (\n",
    "    CONFIG_MAPPING,\n",
    "    AutoConfig,\n",
    "    AutoTokenizer,\n",
    "    DataCollatorForTokenClassification,\n",
    "    HfArgumentParser,\n",
    "    PushToHubCallback,\n",
    "    TFAutoModelForTokenClassification,\n",
    "    TFTrainingArguments,\n",
    "    create_optimizer,\n",
    "    set_seed,\n",
    "    PreTrainedTokenizerFast,\n",
    "    pipeline\n",
    ")\n",
    "from transformers.utils import send_example_telemetry\n",
    "from transformers.utils.versions import require_version\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import mlflow\n",
    "from datasets import load_from_disk, ClassLabel\n",
    "import json\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ],
   "id": "702f6cabe270e8ae",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "TRAIN_DATASET='filtered_dataset_train_modif_2'\n",
    "dataset_dict = load_from_disk(f'/dbfs/mnt/ds-prod-assets/community_signatures/ner_research/{TRAIN_DATASET}/')"
   ],
   "id": "544872188553de09"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "BASE_MODEL='Jean-Baptiste/roberta-large-ner-english'\n",
    "MODEL_NAME = BASE_MODEL\n",
    "NUMBER_SAMPLES_TO_TRAIN = dataset_dict['train'].num_rows"
   ],
   "id": "3c2ebb6b9e9fa187"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "logger = logging.getLogger (__name__)\n",
    "logger.addHandler(logging.StreamHandler())\n",
    "require_version (\"datasets>=1.8.0\", \"To fix: pip install -r examples/tensorflow/token-classification/requirements.txt\")\n",
    "\n",
    "# region Command-line arguments\n",
    "@dataclass\n",
    "class ModelArguments:\n",
    "    \"\"\"\"\n",
    "    Arguments pertaining to which model/config/tokenizer we are going to fine-tune from.\n",
    "    \"\"\"\n",
    "    \n",
    "    model_name_or_path: str = field(\n",
    "        metadata={\"help\": \"Path to pretrained model or model identifier from huggingface.co/models\"}\n",
    "    )\n",
    "    config_name: Optional[str] = field(\n",
    "        default=None, metadata={\"help\": \"Pretrained config name or path if not the same as model_name\"}\n",
    "    )\n",
    "    tokenizer_name: Optional[str] = field(\n",
    "        default=None, metadata={\"help\": \"Pretrained tokenizer name or path if not the same as model_name\"}\n",
    "    )\n",
    "    cache_dir: Optional[str] = field(\n",
    "        default=None, \n",
    "        metadata={\"help\": \"Where do you want to store the pretrained models downloaded from huggingface.co\"}\n",
    "    )\n",
    "    model_revision: str = field(\n",
    "        default=\"main\",\n",
    "        metadata={\"help\": \"The specific model version to use (can be a branch name, tag name or commit id).\"}\n",
    "    )\n",
    "    use_auth_token: bool = field(\n",
    "        default=False,\n",
    "        metadata={\n",
    "            \"help\": (\n",
    "                \"Will use the token generated when running 'huggingface-cli login' (necessary to use this script\"\n",
    "                \"with private models).\"\n",
    "            )\n",
    "        },\n",
    "    )\n",
    "    \n",
    "@dataclass\n",
    "class DataTrainingArguments:\n",
    "    \"\"\"\n",
    "    Arguments pertaining to what data we are going to input our model for training and eval.\n",
    "    \"\"\"\n",
    "    \n",
    "    task_name: Optional[str] = field(default=\"ner\", metadata={\"help\": \"The name of the task (ner, pos...).\"})\n",
    "    dataset_name: Optional[str] = field(\n",
    "        default=None, metadata={\"help\": \"The name of the dataset to use (via the datasets library).\"}\n",
    "    )\n",
    "    dataset_config_name: Optional [str] = field(\n",
    "        default=None, metadata={\"help\": \"The configuration name of the dataset to use (via the datasets library).\"}\n",
    "    )\n",
    "    train_file: Optional[str] = field(\n",
    "        default=None, metadata={\"help\": \"The input training data file (a csv or JSON file).\"}\n",
    "    )\n",
    "    validation_file: Optional[str] = field(\n",
    "        default=None, metadata={\"help\": \"An optional input evaluation data file to evaluate on (a ccs or JSON file).\"}\n",
    "    )\n",
    "    test_file: Optional [str] = field(\n",
    "        default=None, metadata={\"help\": \"An optional input test data file to predict on (a csv or JSON file).\"}\n",
    "    )\n",
    "    text_column_name: Optional[str] = field (\n",
    "        default=None, metadata={\"help\": \"The column name of text to input in the file (a csv or JISON file).\"}\n",
    "    )\n",
    "    label_column_name: Optional [str] = field(\n",
    "        default=None, metadata={\"help\": \"The column name of label to input in the file (a csv or JSON file).\"}\n",
    "    )\n",
    "    overwrite_cache: bool = field(\n",
    "        default=False, metadata={\"help\": \"Overwrite the cached training and evaluation sets\"}\n",
    "    )\n",
    "    preprocessing_num_workers: Optional[int] = field(\n",
    "        default=None, metadata= {\"help\": \"The number of processes to use for the preprocessing.\"}\n",
    "    )\n",
    "    max_length: Optional[int] = field(default=256, metadata={\"help\": \"Max length (in tokens) for truncation/padding\"})\n",
    "    pad_to_max_length: bool = field(\n",
    "        default=False,\n",
    "        metadata={\n",
    "            \"help\": (\n",
    "                \"Whether to pad all samples to model maximum sentence length.\"\n",
    "                \"If False, will pad the samples dynamically when batching to the maximum length in the batch. More \"\n",
    "                \"efficient on GPU but very bad for TPU.\"\n",
    "            )\n",
    "        }\n",
    "    )\n",
    "    max_train_samples: Optional[int] = field(\n",
    "        default=None,\n",
    "        metadata={\n",
    "            \"help\": (\n",
    "                \"For debugging purposes or quicker training, truncate the number of training examples to this \"\n",
    "                \"value if set.\"\n",
    "            )\n",
    "        }\n",
    "    )\n",
    "    max_eval_samples: Optional[int] = field(\n",
    "        default=None, \n",
    "        metadata={\n",
    "            \"help\": (\n",
    "                \"For debugging purposes or quicker training, truncate the number of evaluation examples to this \"\n",
    "                \"value if set.\"\n",
    "            )\n",
    "        }\n",
    "    )\n",
    "    max_predict_samples: Optional [int] = field(\n",
    "        default=None, \n",
    "        metadata={\n",
    "            \"help\": (\n",
    "                \"For debugging purposes or quicker training, truncate the number of prediction examples to this \"\n",
    "                \"value if set.\"\n",
    "            )\n",
    "        }\n",
    "    )\n",
    "    label_all_tokens: bool = field(\n",
    "        default=False, \n",
    "        metadata={\n",
    "            \"help\": (\n",
    "                \"Whether to put the label for one word on all tokens of generated by that word or just on the \"\n",
    "                \"one (in which case the other tokens will have a padding index).\"\n",
    "            )\n",
    "        }\n",
    "    )\n",
    "    return_entity_level_metrics: bool = field(\n",
    "        default=False,\n",
    "        metadata={\"help\": \"Whether to return all the entity levels during evaluation or just the overall ones.\"}\n",
    "    )\n",
    "    \n",
    "#endregion\n",
    "    \n",
    "OUTPUT_DIR = f'/mnt/ds-prod-assets/community_signatures/ner_research/models/{MODEL_NAME}'\n",
    "Path (OUTPUT_DIR).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "# region Argument Parsing\n",
    "model_args = ModelArguments (model_name_or_path=BASE_MODEL)\n",
    "data_args = DataTrainingArguments(pad_to_max_length=True, max_train_samples=NUMBER_SAMPLES_TO_TRAIN)\n",
    "training_args = TFTrainingArguments(output_dir=OUTPUT_DIR)\n",
    "\n",
    "# Sending telemetry. Tracking the example usage helps us better allocate resources to maintain them. The\n",
    "# information sent is the one passed as arguments along with your Python/PyTorch versions.\n",
    "send_example_telemetry(\"run_ner\", model_args, data_args, framework=\"tensorflow\")\n",
    "#endregion\n",
    "\n",
    "# region Setup logging\n",
    "# we only want one process per machine to log things on the screen.\n",
    "# accelerator.is_local_main_process is only True for one process per machine.\n",
    "logger.setLevel(logging.INFO)\n",
    "datasets.utils.logging.set_verbosity_warning()\n",
    "transformers.utils.logging.set_verbosity_info()\n",
    "\n",
    "SEED = 42\n",
    "# If passed along, set the training seed now.\n",
    "if training_args.seed is not None:\n",
    "    set_seed(SEED)\n",
    "#endregion\n",
    "\n",
    "# region Loading datasets\n",
    "# Get the datasets: you can either provide your own CV/JASON/TXT training and evaluation files (see below)\n",
    "# or just provide the name of one of the public datasets for token classification task available on the hub at https://huggingface.co/datasets/ \n",
    "# (the dataset will be downloaded automatically from the datasets Hub).\n",
    "#\n",
    "    # For CSV/JSON files, this script will use the column called 'tokens' or the first column if no column called\n",
    "    # 'tokens' is found. You can easily tweak this behavior (see below).\n",
    "    #\n",
    "    # In distributed training, the load_dataset function guarantee that only one local process can concurrently\n",
    "    # download the dataset.\n",
    "    \n",
    "raw_datasets = dataset_dict\n",
    "\n",
    "if raw_datasets[\"train\"] is not None:\n",
    "        column_names = raw_datasets[\"train\"].column_names\n",
    "        features = raw_datasets[\"train\"].features\n",
    "    else:\n",
    "        column_names = raw_datasets[\"validation\"].column_names\n",
    "        features = raw_datasets[\"validation\"].features\n",
    "        \n",
    "if data_args.text_column_name is not None:\n",
    "        text_column_name = data_args.text_column_name\n",
    "    elif \"tokens\" in column_names:\n",
    "        text_column_name = \"tokens\"\n",
    "    else:\n",
    "        text_column_name = column_names[0]\n",
    "\n",
    "    if data_args.label_column_name is not None:\n",
    "        label_column_name = data_args.label_column_name\n",
    "    elif f\"{data_args.task_name}_tags\" in column_names:\n",
    "        label_column_name = f\"{data_args.task_name}_tags\"\n",
    "    else:\n",
    "        label_column_name = column_names[1]\n",
    "        \n",
    "# In the event the labels are not a `Sequence[ClassLabel]`, we will need to go through the dataset to get the\n",
    "# unique labels.\n",
    "def get_label_list(labels):\n",
    "        unique_labels = set()\n",
    "        for label in labels:\n",
    "            unique_labels = unique_labels | set(label)\n",
    "        label_list = list(unique_labels)\n",
    "        label_list.sort()\n",
    "        return label_list\n",
    "\n",
    "    if isinstance(features[label_column_name].feature, ClassLabel):\n",
    "        label_list = features[label_column_name].feature.names\n",
    "        # No need to convert the labels since they are already ints.\n",
    "        label_to_id = {i: i for i in range(len(label_list))}\n",
    "    else:\n",
    "        label_list = get_label_list(raw_datasets[\"train\"][label_column_name])\n",
    "        label_to_id = {l: i for i, l in enumerate(label_list)}\n",
    "    num_labels = len(label_list)\n",
    "# endregion\n",
    "\n",
    "# region Load config and tokenizer\n",
    "#\n",
    "# In distributed training, the .from_pretrained methods guarantee that only one local process can concurrently\n",
    "# download model & vocab.\n",
    "if model_args.config_name:\n",
    "    config = AutoConfig.from_pretrained(model_args.config_name, num_labels=num_labels)\n",
    "elif model_args.model_name_or_path:\n",
    "    config = AutoConfig.from_pretrained(model_args.model_name_or_path, num_labels=num_labels, id2label={i: label for i, label in enumerate(label_list)},\n",
    "                                            label2id={label: i for i, label in enumerate(label_list)})\n",
    "else:\n",
    "    config = CONFIG_MAPPING[model_args.model_type]()\n",
    "    logger.warning(\"You are instantiating a new config instance from scratch.\")\n",
    "            \n",
    "tokenizer_name_or_path = model_args.tokenizer_name if model_args.tokenizer_name else model_args.model_name_or_path\n",
    "if not tokenizer_name_or_path:\n",
    "    raise ValueError(\n",
    "        \"You are instantiating a new tokenizer from scratch. This is not supported by this script. \"\n",
    "        \"You can do it from another script, save it, and load it from here, using --tokenizer_name.\"\n",
    "    )\n",
    "\n",
    "if config.model_type in {\"gpt2\", \"roberta\", \"deberta\"}:\n",
    "    tokenizer = AutoTokenizer.from_pretrained(tokenizer_name_or_path, use_fast=True, add_prefix_space=True)\n",
    "else:\n",
    "    tokenizer = AutoTokenizer.from_pretrained(tokenizer_name_or_path, use_fast=True)\n",
    "\n",
    "# endregion\n",
    "\n",
    "# region Preprocessing the raw datasets\n",
    "# First we tokenize all the texts.\n",
    "padding = \"max_length\" if data_args.pad_to_max_length else False\n",
    "\n",
    "# Tokenize all texts and align the labels with them.\n",
    "\n",
    "def tokenize_and_align_labels(examples):\n",
    "    tokenized_inputs = tokenizer(\n",
    "        examples[text_column_name],\n",
    "        max_length=data_args.max_length,\n",
    "        padding=padding,\n",
    "        truncation=True,\n",
    "        # We use this argument because the texts in our dataset are lists of words (with a label for each word).\n",
    "        is_split_into_words=True,\n",
    "    )\n",
    "\n",
    "    labels = []\n",
    "    for i, label in enumerate(examples[label_column_name]):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
    "        previous_word_idx = None\n",
    "        label_ids = []\n",
    "        for word_idx in word_ids:\n",
    "            # Special tokens have a word id that is None. We set the label to -100 so they are automatically\n",
    "            # ignored in the loss function.\n",
    "            if word_idx is None:\n",
    "                label_ids.append(-100)\n",
    "            # We set the label for the first token of each word.\n",
    "            elif word_idx != previous_word_idx:\n",
    "                label_ids.append(label_to_id[label[word_idx]])\n",
    "            # For the other tokens in a word, we set the label to either the current label or -100, depending on\n",
    "            # the label_all_tokens flag.\n",
    "            else:\n",
    "                label_ids.append(label_to_id[label[word_idx]] if data_args.label_all_tokens else -100)\n",
    "            previous_word_idx = word_idx\n",
    "\n",
    "        labels.append(label_ids)\n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    return tokenized_inputs\n",
    "\n",
    "processed_raw_datasets = raw_datasets.map(\n",
    "    tokenize_and_align_labels,\n",
    "    batched=True,\n",
    "    remove_columns=raw_datasets[\"train\"].column_names,\n",
    "    desc=\"Running tokenizer on dataset\",\n",
    ")\n",
    "\n",
    "train_dataset = processed_raw_datasets[\"train\"]\n",
    "eval_dataset = processed_raw_datasets[\"validation\"]\n",
    "test_dataset = processed_raw_datasets[\"test\"]\n",
    "\n",
    "if data_args.max_train_samples is not None:\n",
    "    max_train_samples = min(len(train_dataset), data_args.max_train_samples)\n",
    "    train_dataset = train_dataset.select(range(max_train_samples))\n",
    "\n",
    "if data_args.max_eval_samples is not None:\n",
    "    max_eval_samples = min(len(eval_dataset), data_args.max_eval_samples)\n",
    "    eval_dataset = eval_dataset.select(range(max_eval_samples))\n",
    "\n",
    "# Log a few random samples from the training set:\n",
    "random.seed(SEED)\n",
    "for index in random.sample(range(len(train_dataset)), 3):\n",
    "    logger.info(f\"Sample {index} of the training set: {train_dataset[index]}.\")\n",
    "# endregion\n",
    "\n",
    "with training_args.strategy.scope():\n",
    "    # region Initialize model\n",
    "    if model_args.model_name_or_path:\n",
    "        model = TFAutoModelForTokenClassification.from_pretrained(\n",
    "            model_args.model_name_or_path,\n",
    "            config=config,\n",
    "        )\n",
    "    else:\n",
    "        logger.info(\"Training new model from scratch\")\n",
    "        model = TFAutoModelForTokenClassification.from_config(config)\n",
    "\n",
    "    # We resize the embeddings only when necessary to avoid index errors. If you are creating a model from scratch\n",
    "    # on a small vocab and want a smaller embedding size, remove this test.\n",
    "    embeddings = model.get_input_embeddings()\n",
    "\n",
    "    # Matt: This is a temporary workaround as we transition our models to exclusively using Keras embeddings.\n",
    "    #       As soon as the transition is complete, all embeddings should be keras.Embeddings layers, and\n",
    "    #       the weights will always be in embeddings.embeddings.\n",
    "    if hasattr(embeddings, \"embeddings\"):\n",
    "        embedding_size = embeddings.embeddings.shape[0]\n",
    "    else:\n",
    "        embedding_size = embeddings.weight.shape[0]\n",
    "    if len(tokenizer) > embedding_size:\n",
    "        model.resize_token_embeddings(len(tokenizer))\n",
    "    # endregion\n",
    "\n",
    "    # region Create TF datasets\n",
    "\n",
    "    # We need the DataCollatorForTokenClassification here, as we need to correctly pad labels as\n",
    "    # well as inputs.\n",
    "    collate_fn = DataCollatorForTokenClassification(tokenizer=tokenizer, return_tensors=\"np\")\n",
    "    num_replicas = training_args.strategy.num_replicas_in_sync\n",
    "    total_train_batch_size = training_args.per_device_train_batch_size * num_replicas\n",
    "\n",
    "    dataset_options = tf.data.Options()\n",
    "    dataset_options.experimental_distribute.auto_shard_policy = tf.data.experimental.AutoShardPolicy.OFF\n",
    "\n",
    "    # model.prepare_tf_dataset() wraps a Hugging Face dataset in a tf.data.Dataset which is ready to use in\n",
    "    # training. This is the recommended way to use a Hugging Face dataset when training with Keras. You can also\n",
    "    # use the lower-level dataset.to_tf_dataset() method, but you will have to specify things like column names\n",
    "    # yourself if you use this method, whereas they are automatically inferred from the model input names when\n",
    "    # using model.prepare_tf_dataset()\n",
    "    # For more info see the docs:\n",
    "    # https://huggingface.co/docs/transformers/main/en/main_classes/model#transformers.TFPreTrainedModel.prepare_tf_dataset\n",
    "    # https://huggingface.co/docs/datasets/main/en/package_reference/main_classes#datasets.Dataset.to_tf_dataset\n",
    "\n",
    "    tf_train_dataset = model.prepare_tf_dataset(\n",
    "        train_dataset,\n",
    "        collate_fn=collate_fn,\n",
    "        batch_size=total_train_batch_size,\n",
    "        shuffle=True,\n",
    "    ).with_options(dataset_options)\n",
    "    total_eval_batch_size = training_args.per_device_eval_batch_size * num_replicas\n",
    "    tf_eval_dataset = model.prepare_tf_dataset(\n",
    "        eval_dataset,\n",
    "        collate_fn=collate_fn,\n",
    "        batch_size=total_eval_batch_size,\n",
    "        shuffle=False,\n",
    "    ).with_options(dataset_options)\n",
    "    total_test_batch_size = total_eval_batch_size\n",
    "    tf_test_dataset = model.prepare_tf_dataset(\n",
    "        test_dataset,\n",
    "        collate_fn=collate_fn,\n",
    "        batch_size=total_test_batch_size,\n",
    "        shuffle=False,\n",
    "    ).with_options(dataset_options)\n",
    "    \n",
    "    # endregion\n",
    "    num_train_epochs = 20\n",
    "    # region Optimizer, loss and compilation\n",
    "    num_train_steps = int(len(tf_train_dataset) * num_train_epochs)\n",
    "    if training_args.warmup_steps > 0:\n",
    "        num_warmup_steps = training_args.warmup_steps\n",
    "    elif training_args.warmup_ratio > 0:\n",
    "        num_warmup_steps = int(num_train_steps * training_args.warmup_ratio)\n",
    "    else:\n",
    "        num_warmup_steps = 0\n",
    "    \n",
    "    optimizer, lr_schedule = create_optimizer(\n",
    "        init_lr=training_args.learning_rate,\n",
    "        num_train_steps=num_train_steps,\n",
    "        num_warmup_steps=num_warmup_steps,\n",
    "        adam_beta1=training_args.adam_beta1,\n",
    "        adam_beta2=training_args.adam_beta2,\n",
    "        adam_epsilon=training_args.adam_epsilon,\n",
    "        weight_decay_rate=training_args.weight_decay,\n",
    "        adam_global_clipnorm=training_args.max_grad_norm,\n",
    "    )\n",
    "    # Transformers models compute the right loss for their task by default when labels are passed, and will\n",
    "    # use this for training unless you specify your own loss function in compile().\n",
    "    model.compile(optimizer=optimizer, jit_compile=training_args.xla)\n",
    "    # endregion\n",
    "        \n",
    "    # Metrics\n",
    "    metric = evaluate.load(\"seqeval\")\n",
    "\n",
    "    def get_labels(y_pred, y_true):\n",
    "        # Transform predictions and references tensos to numpy arrays\n",
    "\n",
    "        # Remove ignored index (special tokens)\n",
    "        true_predictions = [\n",
    "            [label_list[p] for (p, l) in zip(pred, gold_label) if l != -100]\n",
    "            for pred, gold_label in zip(y_pred, y_true)\n",
    "        ]\n",
    "        true_labels = [\n",
    "            [label_list[l] for (p, l) in zip(pred, gold_label) if l != -100]\n",
    "            for pred, gold_label in zip(y_pred, y_true)\n",
    "        ]\n",
    "        return true_predictions, true_labels\n",
    "\n",
    "    def compute_metrics():\n",
    "        results = metric.compute()\n",
    "        if data_args.return_entity_level_metrics:\n",
    "            # Unpack nested dictionaries\n",
    "            final_results = {}\n",
    "            for key, value in results.items():\n",
    "                if isinstance(value, dict):\n",
    "                    for n, v in value.items():\n",
    "                        final_results[f\"{key}_{n}\"] = v\n",
    "                else:\n",
    "                    final_results[key] = value\n",
    "            return final_results\n",
    "        else:\n",
    "            return {\n",
    "                \"precision\": results[\"overall_precision\"],\n",
    "                \"recall\": results[\"overall_recall\"],\n",
    "                \"f1\": results[\"overall_f1\"],\n",
    "                \"accuracy\": results[\"overall_accuracy\"],\n",
    "            }\n",
    "    \n",
    "    # endregion\n",
    "\n",
    "    # region Preparing push_to_hub and model card\n",
    "    push_to_hub_model_id = training_args.push_to_hub_model_id\n",
    "    model_name = model_args.model_name_or_path.split(\"/\")[-1]\n",
    "    if not push_to_hub_model_id:\n",
    "        if data_args.dataset_name is not None:\n",
    "            push_to_hub_model_id = f\"{model_name}-finetuned-{data_args.dataset_name}\"\n",
    "        else:\n",
    "            push_to_hub_model_id = f\"{model_name}-finetuned-token-classification\"\n",
    "\n",
    "    model_card_kwargs = {\"finetuned_from\": model_args.model_name_or_path, \"tasks\": \"token-classification\"}\n",
    "    if data_args.dataset_name is not None:\n",
    "        model_card_kwargs[\"dataset_tags\"] = data_args.dataset_name\n",
    "        if data_args.dataset_config_name is not None:\n",
    "            model_card_kwargs[\"dataset_args\"] = data_args.dataset_config_name\n",
    "            model_card_kwargs[\"dataset\"] = f\"{data_args.dataset_name} {data_args.dataset_config_name}\"\n",
    "        else:\n",
    "            model_card_kwargs[\"dataset\"] = data_args.dataset_name\n",
    "\n",
    "    if training_args.push_to_hub:\n",
    "        callbacks = [\n",
    "            PushToHubCallback(\n",
    "                output_dir=training_args.output_dir,\n",
    "                hub_model_id=push_to_hub_model_id,\n",
    "                hub_token=training_args.push_to_hub_token,\n",
    "                tokenizer=tokenizer,\n",
    "                **model_card_kwargs,\n",
    "            )\n",
    "        ]\n",
    "    else:\n",
    "        callbacks = [EarlyStopping(monitor='val_loss', patience=2, restore_best_weights=True)]\n",
    "    # endregion\n",
    "    \n",
    "    # region Training\n",
    "    logger.info(\"***** Running training *****\")\n",
    "    logger.info(f\"  Num examples = {len(train_dataset)}\")\n",
    "    logger.info(f\"  Num Epochs = {training_args.num_train_epochs}\")\n",
    "    logger.info(f\"  Instantaneous batch size per device = {training_args.per_device_train_batch_size}\")\n",
    "    logger.info(f\"  Total train batch size = {total_train_batch_size}\")\n",
    "    # Only show the progress bar once on each machine.\n",
    "    \n",
    "    mlflow.autolog(exclusive=False)\n",
    "    with mlflow.start_run() as parent_run:\n",
    "        mlflow.set_tag(\"model_name\", MODEL_NAME)\n",
    "        mlflow.set_tag(\"train_dataset_name\", TRAIN_DATASET)\n",
    "        mlflow.log_param(\"num_train_samples\", len(train_dataset))\n",
    "        mlflow.log_param(\"num_validation_samples\", len(eval_dataset))\n",
    "        mlflow.log_param(\"num_test_samples\", len(test_dataset))\n",
    "        model.fit(\n",
    "            tf_train_dataset,\n",
    "            validation_data=tf_eval_dataset,\n",
    "            epochs=int(num_train_epochs),\n",
    "            callbacks=callbacks,\n",
    "        )\n",
    "        # endregion\n",
    "\n",
    "        # region Predictions\n",
    "        # If you have variable batch sizes (i.e. not using pad_to_max_length), then\n",
    "        # this bit might fail on TF < 2.8 because TF can't concatenate outputs of varying seq\n",
    "        # length from predict().\n",
    "\n",
    "        tf_eval_test_data = [tf_eval_dataset, tf_test_dataset]\n",
    "        eval_test_data = [eval_dataset, test_dataset]\n",
    "        eval_test = ['val', 'test']\n",
    "        \n",
    "        for i in range(2):\n",
    "            try:\n",
    "                predictions = model.predict(tf_eval_test_data[i], batch_size=training_args.per_device_eval_batch_size)[\"logits\"]\n",
    "            except tf.python.framework.errors_impl.InvalidArgumentError:\n",
    "                raise ValueError(\n",
    "                    \"Concatenating predictions failed! If your version of TensorFlow is 2.8.0 or older \"\n",
    "                    \"then you will need to use --pad_to_max_length to generate predictions, as older \"\n",
    "                    \"versions of TensorFlow cannot concatenate variable-length predictions as RaggedTensor.\"\n",
    "                )\n",
    "            if isinstance(predictions, tf.RaggedTensor):\n",
    "                predictions = predictions.to_tensor(default_value=-100)\n",
    "        predictions = tf.math.argmax(predictions, axis=-1).numpy()\n",
    "        if \"label\" in eval_test_data[i]:\n",
    "            labels = eval_test_data[i].with_format(\"tf\")[\"label\"]\n",
    "        else:\n",
    "            labels = eval_test_data[i].with_format(\"tf\")[\"labels\"]\n",
    "        if isinstance(labels, tf.RaggedTensor):\n",
    "            labels = labels.to_tensor(default_value=-100)\n",
    "        labels = labels.numpy()\n",
    "        attention_mask = eval_test_data[i].with_format(\"tf\")[\"attention_mask\"]\n",
    "        if isinstance(attention_mask, tf.RaggedTensor):\n",
    "            attention_mask = attention_mask.to_tensor(default_value=-100)\n",
    "        attention_mask = attention_mask.numpy()\n",
    "        labels[attention_mask == 0] = -100\n",
    "        preds, refs = get_labels(predictions, labels)\n",
    "        metric.add_batch(\n",
    "            predictions=preds,\n",
    "            references=refs,\n",
    "        )\n",
    "        eval_metric = compute_metrics()\n",
    "        logger.info(f\"Evaluation metrics: ({eval_test}):\")\n",
    "        for key, val in eval_metric.items():\n",
    "            logger.info(f\"{key}: {val:.4f}\")\n",
    "            mlflow.log_metric(f\"{eval_test[i]}_seqeval_{key}\", val)\n",
    "        \n",
    "        if training_args.output_dir is not None:\n",
    "            output_eval_file = os.path.join(training_args.output_dir, \"all_results.json\")\n",
    "            with open(output_eval_file, \"w\") as writer:\n",
    "                writer.write(json.dumps(eval_metric))\n",
    "        # endregion\n",
    "        \n",
    "        filtered_preds = [pred for seq in preds for pred in seq if pred != -100]\n",
    "        filtered_refs = [ref for seq in refs for ref in seq if ref != -100]\n",
    "        \n",
    "        le = LabelEncoder()\n",
    "        encoded_refs = le.fit_transform(filtered_refs)\n",
    "        encoded_preds = le.transform(filtered_preds)\n",
    "        \n",
    "        report =classification_report(encoded_refs, encoded_preds, target_names=le.classes_)\n",
    "        with open(f\"{eval_test[i]}_report.txt\", \"w\") as f:\n",
    "            f.write(report)\n",
    "        mlflow.log_artifact(f\"{eval_test[i]}_report.txt\")\n",
    "        \n",
    "        conf_matrix = confusion_matrix(encoded_refs, encoded_preds)\n",
    "        df_cm = pd.DataFrame(conf_matrix, columns=le.classes_, index=le.classes_)\n",
    "        fig = plt.figure(figsize = (10,7))\n",
    "        sns.set(font_scale=1.4)\n",
    "        sns.heatmap(df_cm, annot=True, annot_kws={\"size\":16}, fmt='g')\n",
    "        plt.xlabel('Predicted')\n",
    "        plt.ylabel('Actual')\n",
    "        plt.savefig(f'{eval_test[i]}_confusion_matrix.png')\n",
    "        mlflow.log_artifact(f'{eval_test[i]}_confusion_matrix.png')\n",
    "        plt.close(fig)\n",
    "        \n",
    "        # endregion\n",
    "        \n",
    "        if training_args.output_dir is not None and not training_args.push_to_hub:\n",
    "            # If we're not pushing to hub, at least save a local copy when we're done\n",
    "            model.save_pretrained(training_args.output_dir)        "
   ],
   "id": "386675b5ebc5e3a0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "local_output_dir = os.path.abspath(training_args.output_dir)\n",
    "dbfs_output_dir = f\"{OUTPUT_DIR}\"\n",
    "\n",
    "dbutils.fs.cp(f\"file:{local_output_dir}\", dbfs_output_dir, recurse=True)"
   ],
   "id": "625b9113af5c61f0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "2d45aa10e300d539"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "2697477c9e011225"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
